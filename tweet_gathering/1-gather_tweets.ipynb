{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweets gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Twitter ?\n",
    "We gather tweets since Twitter is known to be a financial information hub. \n",
    "We may emphazise on the fact that in general investor's behavior reflects on the market.\n",
    "\n",
    "More details may be found on these papers.\n",
    "> Bollen, Johan, Huina Mao, and Xiaojun Zeng. \"Twitter mood predicts the stock market.\" *Journal of computational science 2.1 (2011)*: 1-8.\n",
    "\n",
    "> Atkins, Adam, Mahesan Niranjan, and Enrico Gerding. \"Financial news predicts stock market volatility better than close price.\" *The Journal of Finance and Data Science 4.2 (2018)*: 120-137.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Fetching the tweets\n",
    "## Comments\n",
    "In this part we are gathering the tweets using the **tweepy library**. Since the API call rate of twitter is limited to 180 calls every 15 minutes.\n",
    "We save the resulting process into a csv file of raw tweets namely in the **twitter_data.csv** in *7-Data/1-RawTweets*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tweepy\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We import the cryptocurrency name and symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import the csv(s) and select the relevant columns\n",
    "# crypto list\n",
    "df_crypto = pd.read_csv(\"./data/crypto.csv\")\n",
    "df_crypto = df_crypto[['symbol','symbol']]\n",
    "df_crypto.columns = ['Symbol','Name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We authenticate on Twitter with our credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "consumer_key = \"z7gp32ZtNDlQOj4W92v6wJqm5\" \n",
    "consumer_secret = \"vbDEgRXlqALekExDz2wqhTiU6CwpBsLeEVNOF1al9hapqywsl6\" \n",
    "\n",
    "access_token = \"901719311143903233-V2t305dvpgFtMwonEIXoof8FOAKZxiH\"\n",
    "access_token_secret = \"z9knLifKkDRtJwgTQqxZxpA0Gy05HWVqsVj9K5M8fX0up\"\n",
    "\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We define our main functions\n",
    "1. **parse_tweet** : That we'll use to parse each tweets\n",
    "2. **format_response** : That we will use to transform in a company/tweet format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there is an error creating the api instance\n",
    "if (not api):\n",
    "    print (\"Can't Authenticate\")\n",
    "    sys.exit(-1)\n",
    "\n",
    "# define parsing functions\n",
    "def parse_tweet(tweet):\n",
    "    \"\"\"\n",
    "    Takes result object from tweepy and parses it\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize dict\n",
    "    parsed_tweet = {}\n",
    "\n",
    "    # extract relevant info\n",
    "    parsed_tweet['Author Name'] = tweet.author.name\n",
    "    parsed_tweet['Text'] = tweet.text\n",
    "    parsed_tweet['Message ID'] = tweet.id\n",
    "    parsed_tweet['Published At'] = tweet.created_at\n",
    "    parsed_tweet['Retweet Count'] = tweet.retweet_count\n",
    "    parsed_tweet['Favorite Count'] = tweet.favorite_count\n",
    "\n",
    "    return parsed_tweet\n",
    "\n",
    "def format_response(response, crypto):\n",
    "    \"\"\"\n",
    "    Takes list of result objects from tweepy and formats it\n",
    "    \"\"\"\n",
    "    try:\n",
    "        parsed_tweets = pd.DataFrame([parse_tweet(tweet) for tweet in response], columns=[ 'Crypto', 'Author Name', 'Text', 'Message ID', 'Published At', 'Retweet Count', 'Favorite Count'])\n",
    "        parsed_tweets['Crypto'] = str(crypto)\n",
    "    except TypeError as e:\n",
    "        print(e)\n",
    "        parsed_tweets = pd.DataFrame(columns=[ 'Crypto', 'Author Name', 'Text', 'Message ID', 'Published At', 'Retweet Count', 'Favorite Count'])\n",
    "\n",
    "    return parsed_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main algorithm\n",
    "We now run the process of fetching tweets. Then we save it into a csv file namely: **twitter_data.csv** contained in the folder */7-Data/1-RawTweets*.\n",
    "\n",
    "This process is **quite time intensive**, so the user may totally **skip** it since tweets already have been fetched beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing CHSB 0 of 7\n",
      "Processing MCO 1 of 7\n",
      "Processing EDO 2 of 7\n",
      "Processing CRPT 3 of 7\n",
      "Processing NEXO 4 of 7\n",
      "Processing SXP 5 of 7\n",
      "Processing DROP 6 of 7\n",
      "Sleeping for 2 minutes\n"
     ]
    }
   ],
   "source": [
    "# main program\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    while True:\n",
    "\n",
    "        # We create a timestamp\n",
    "        ts = int(time.time())\n",
    "\n",
    "        # if twitter data exists\n",
    "        try:\n",
    "            data = pd.read_csv('./data/update.csv')\n",
    "        except:\n",
    "            data = False\n",
    "\n",
    "        # loop over companies\n",
    "        for idx,crypto in enumerate(df_crypto['Name']):\n",
    "\n",
    "            print('Processing {0} {1} of {2}'.format(crypto, str(idx), str(len(df_crypto['Name']))))\n",
    "\n",
    "            # define params dict\n",
    "            params={\n",
    "                'q' : crypto+\" cryptocurrency\"\n",
    "            }\n",
    "\n",
    "            # add max_id if prior data file exists\n",
    "            if data is not False:\n",
    "\n",
    "                # if this company exists in our dataset\n",
    "                if crypto in data['Crypto']:\n",
    "\n",
    "                    # add the max_id param so we dont collect redundant tweets\n",
    "                    params['since_id'] = data[data['Crypto']==crypto]['Message ID'].max()\n",
    "\n",
    "            try:\n",
    "                # make the call to twitter\n",
    "                response = api.search(**params)\n",
    "\n",
    "            # handle error\n",
    "            except tweepy.error.TweepError as e:\n",
    "\n",
    "                print(e)\n",
    "\n",
    "                # Will run up to the point where it reaches the Rate limit per 15 min.\n",
    "                response = api.search(**params)\n",
    "\n",
    "            # format response\n",
    "            formatted_response = format_response(response, crypto)\n",
    "\n",
    "            # write out the result\n",
    "            if data is not False:\n",
    "                formatted_response.to_csv('./data/1-raw-tweets/twitter_data_{}.csv'.format(ts), mode='a', header=False, encoding='utf-8')\n",
    "            elif idx == 0:\n",
    "                formatted_response.to_csv('./data/1-raw-tweets/twitter_data_{}.csv'.format(ts), encoding='utf-8')\n",
    "            else:\n",
    "                formatted_response.to_csv('./data/1-raw-tweets/twitter_data_{}.csv'.format(ts), mode='a', header=False, encoding='utf-8')\n",
    "                \n",
    "        print(\"Sleeping for 2 minutes\")\n",
    "        time.sleep(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".data-science",
   "language": "python",
   "name": ".data-science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
